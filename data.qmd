# Data

## Description
(ACS) 5-Year Housing Estimates. The data is collected and maintained by the U.S. 
Census Bureau, which conducts comprehensive surveys to assess housing 
characteristics across counties in the United States and the specific dataset we 
are using is for the years 2016-2020. The dataset is provided in a CSV format and 
includes over 240 columns with variables such as total housing units, occupancy 
rates, and housing costs. These variables are measured and updated annually, 
with detailed geographic identifiers for each county. The data is 
well-documented, and the source is reliable for understanding housing trends at 
a granular level. To import the data, I used standard data manipulation tools. 
Some challenges include the large number of columns and potential for missing 
values, which require preprocessing for effective analysis. Additionally, the 
original column names in the dataset are not clear and understandable so we need 
to rename the columns for clarity. The dataset can be accessed directly from the 
U.S. Census Bureau's data repository.

## Loading data
```{r}
library(dplyr)
library(readxl)
library(tidyverse)

info_path = "rawData/DD_ACS_5-Year_Housing_Estimate_Data_by_County.xlsx"
data_path = "rawData/ACS_5YR_Housing_Estimate_Data_by_County_-8702403216850992228.csv"

column_info <- read_excel(info_path)
data <- read.csv(data_path)
```

## Cleaning Data
```{r}
colnames(column_info) <- gsub(" ", "_", colnames(column_info))

column_info <- column_info |>
  filter(!grepl("as a %", Column_Description)) |>
  filter(!grepl("B25068|B25058", Column_Name))

data <- data |>
  select(-contains("B25068"), -contains("B25058")) |> 
  select(-contains("PCT"))

column_info$Column_Description <- gsub(" ", "_", column_info$Column_Description)

column_info$Column_Description <- gsub("[^[:alnum:]_]", 
                                       "", 
                                       column_info$Column_Description)
table_name_mapping <- c(
  "B25002" = "Occupancy_Status",
  "B25009" = "Tenure_By_Household_Size",
  "B25021" = "Median_Number_Of_Rooms_By_Tenure",
  "B25024" = "Units_In_Structure",
  "B25032_OWN_" = "Owner_Tenure_By_Units_In_Structure",
  "B25032_RENT" = "Renter_Tenure_By_Units_In_Structure",
  "B25036_OWN_" = "Owner_Tenure_By_Year_Structure_Built",
  "B25036_RENT" = "Renter_Tenure_By_Year_Structure_Built",
  "B25037" = "Median_Year_Structure_Built_By_Tenure",
  "B25041" = "Bedrooms",
  "B25042" = "Tenure_By_Bedrooms",
  "B25056" = "Contract_Rent",
  "B25123" = "Tenure_By_Selected_Physical_And_Financial_Conditions"
)

owner_columns <- c("B25032EST2", "B25032EST3", "B25032EST4")
renter_columns <- c("B25032EST13", "B25032EST14", "B25032EST15")

column_info$Column_Name <- sapply(column_info$Column_Name, function(colname) {
  if (colname %in% owner_columns) {
    return(gsub("B25032EST", "B25032_OWN_EST", colname))  # For Owner columns
  } else if (colname %in% renter_columns) {
    return(gsub("B25032EST", "B25032_RENT_EST", colname))  # For Renter columns
  }
  return(colname)  # Keep other column names unchanged
})


# Function to update column names in data df
colnames(data) <- sapply(colnames(data), function(colname) {
  if (colname %in% owner_columns) {
    # If the column is in the Owner list, append '_OWN_' to the name
    return(gsub("B25032EST", "B25032_OWN_EST", colname))
  } else if (colname %in% renter_columns) {
    # If the column is in the Renter list, append '_RENT_' to the name
    return(gsub("B25032EST", "B25032_RENT_EST", colname))
  }
  return(colname)
})

modify_column_description <- function(column_name, description) {
  prefix <- substr(column_name, 1, 6)
  prefix11 <- substr(column_name, 1, 11)

  table_name <- table_name_mapping[prefix]
  table_name_11 <- table_name_mapping[prefix11]
  if (!is.na(table_name_11) && prefix %in% c("B25036", "B25032")) {
    new_description <- paste(table_name_11, "(", description, ")", sep = "")
    return(new_description)
  } else if (!is.na(table_name)) {
    new_description <- paste(table_name, "(", description, ")", sep = "")
    return(new_description)
  }
  return(description)
}

column_info$Column_Description <- mapply(modify_column_description, 
                                         column_info$Column_Name, 
                                         column_info$Column_Description)

exclude_columns <- 
  c("OBJECTID", "GEOID", "STATE", "COUNTY", "NAME", "STUSAB", "STATE_NAME")

column_info_filtered <- column_info |>
  filter(!Column_Name %in% exclude_columns)

column_name_to_description <- setNames(column_info_filtered$Column_Description, 
                                       column_info_filtered$Column_Name)

colnames(data) <- ifelse(colnames(data) %in% names(column_name_to_description),
                         column_name_to_description[colnames(data)],
                         colnames(data))

data <- data %>%
  select(-c("B25123_TOT", "B25123_TOT_1", "B25123_TOT_2", 
            "B25123_TOT_3", "B25123_TOT_4"))

print("Renamed Columns:")
print(colnames(data))
write.csv(data, "data.csv", row.names = FALSE)

```

## Creating data for d3Graph
```{r}
library(jsonlite)

state_data <- data |>
  group_by(STATE_NAME) |>
  summarise(
    state_median = median(Median_value_for_units_with_a_mortgage, na.rm = TRUE),
    .groups = "drop"
  )

top_counties_data <- data |>
  group_by(STATE_NAME) |>
  arrange(desc(Median_value_for_units_with_a_mortgage)) |>
  slice_head(n = 5) |>
  select(STATE_NAME, county = NAME, value = Median_value_for_units_with_a_mortgage) |>
  nest(top_counties = c(county, value))

state_json <- state_data |>
  left_join(top_counties_data, by = "STATE_NAME")

write_json(state_json, "d3Data/d3Data.json", pretty = TRUE)
```

```{r}
missing_summary <- data |>
  summarise_all(~sum(is.na(.))) |>
  pivot_longer(cols = everything(), 
               names_to = "Variable", 
               values_to = "Missing_Count") |>
  arrange(desc(Missing_Count))

data_with_missing <- data |>
  select(where(~ any(is.na(.))))

columns_with_missing <- missing_summary |>
  filter(Missing_Count > 0)

# Print only columns with missing values
print(columns_with_missing)
```
```{r}
ggplot(columns_with_missing, aes(x = reorder(Variable, -Missing_Count), y = Missing_Count)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  coord_flip() +
  labs(title = "Missing Values per Column (Filtered)", x = "Columns", y = "Count of Missing Values") +
  theme_minimal()
```
  This bar chart shows the count of missing values for the columns that have 
data missing. It is able to show that the mssing values are concentrated
into these few variables but 
Mortgage_Status_By_Median_Value(Median_value_for_units_with_a_mortgage) has the
most at 10 missing. The overall low missing values shows that the data quality
is very high and there really is no need to inpute or remove.  

```{r}
missing_percentage <- data_with_missing |>
  summarise_all(~ mean(is.na(.)) * 100) |>
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Percentage_Missing")

# Bar plot for missing percentage
ggplot(missing_percentage, aes(x = reorder(Variable, -Percentage_Missing), y = Percentage_Missing)) +
  geom_bar(stat = "identity", fill = "tomato") +
  coord_flip() +
  labs(title = "Percentage of Missing Values per Column", x = "Columns", y = "Percentage Missing") +
  theme_minimal()
```
This graph shows how missing data is very minimal for all the columns that
include missing values. The highest missing percentage is less than 0.3% this 
shows how reliable and unnecessary imputation of extra cleaning is.